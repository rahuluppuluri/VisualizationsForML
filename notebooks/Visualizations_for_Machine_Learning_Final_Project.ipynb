{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualizations for Machine Learning Final Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg3YL5krW3cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e4645e-8b21-413c-efbf-a5af53846942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.1 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 10.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 679 kB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 17.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 42.7 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.33.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj_4hku-W8OL",
        "outputId": "5500a967-cd5e-4959-b6a8-52d04aa6f4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting shap\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.1)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=b3bf758ea800376525836b5d491ef24ccbe3699dcc4522ce69b66824eaf96735\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built lime\n",
            "Installing collected packages: slicer, shap, lime\n",
            "Successfully installed lime-0.2.0.1 shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "census_train = pd.read_csv(filepath_or_buffer=\"/content/drive/MyDrive/census-income.data\")\n",
        "census_test = pd.read_csv(filepath_or_buffer=\"/content/drive/MyDrive/census-income.test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpyatUfnkMpo",
        "outputId": "0df34ccb-168c-45f2-afe3-87039217f13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from matplotlib import axes\n",
        "import matplotlib.pyplot as plt\n",
        "import streamlit as st\n",
        "from sklearn.datasets import make_classification\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from lime import lime_tabular\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "import shap\n",
        "import math\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "page_names = ['Synthetic', 'Real World']\n",
        "page = st.radio('Data Type', page_names)\n",
        "\n",
        "# ALL CODE BELOW WILL BE FOR SYNTETIC\n",
        "if page == 'Synthetic':\n",
        "\n",
        "  # Create interactive inputs for num features, redundant, repetitive, etc.\n",
        "  num_samples = st.slider('Choose the number of samples', 0, 20000, 1000)\n",
        "\n",
        "  num_feats = st.slider('Number of features', \n",
        "                  min_value= int((math.log(4)/math.log(2))), \n",
        "                  max_value=100, \n",
        "                  value=4)\n",
        "  num_inform = st.slider('Number of informative features', \n",
        "                  min_value=0, \n",
        "                  max_value=num_feats, \n",
        "                  value=2)\n",
        "  num_red = st.slider('Number of redundant features', \n",
        "                  min_value=0, \n",
        "                  max_value=(num_feats - num_inform), \n",
        "                  value=1)\n",
        "  num_rep = st.slider('Number of repetitive features', \n",
        "                  min_value=0, \n",
        "                  max_value= (num_feats - num_inform - num_red), \n",
        "                  value=1)\n",
        "  flip_val = st.slider('Flip_y value', \n",
        "                  min_value=-1.0, \n",
        "                  max_value= 1.0, \n",
        "                  value=.01)\n",
        "  weights_val = st.slider('Binary Classification weight for class 0', \n",
        "                  min_value=0.0, \n",
        "                  max_value= 1.0, \n",
        "                  value=.50)\n",
        "\n",
        "  # Create the synthetic data\n",
        "  x,y = make_classification(n_samples=num_samples, \n",
        "                            n_features= num_feats,\n",
        "                            n_informative= num_inform, \n",
        "                            n_redundant= num_red, \n",
        "                            n_repeated= num_rep, \n",
        "                            n_classes=2, \n",
        "                            n_clusters_per_class=2, \n",
        "                            weights= [weights_val, 1 - weights_val], \n",
        "                            flip_y= flip_val, \n",
        "                            class_sep=1.0, \n",
        "                            hypercube=True, \n",
        "                            shift=0.0, \n",
        "                            scale=1.0, \n",
        "                            shuffle=True, \n",
        "                            random_state=2022)\n",
        "\n",
        "\n",
        "  #load the synthetic data to web-app\n",
        "  def load_x_data(nrows):\n",
        "      data = x[0:nrows]\n",
        "      return data\n",
        "\n",
        "  def load_y_data(nrows):\n",
        "      data = y[0:nrows]\n",
        "      return data\n",
        "    \n",
        "  x_data = load_x_data(1000)\n",
        "  y_data = load_y_data(1000)\n",
        "\n",
        "\n",
        "  #write scatter plot of synthetic data to web-app\n",
        "  feature_to_filter_one = st.slider('Choose x-axis feature', 0, x_data.shape[1] - 1, 0)\n",
        "  feature_to_filter_two = st.slider('Choose y-axis feature', 0, x_data.shape[1] - 1, 1)\n",
        "\n",
        "  source = pd.DataFrame(x_data)\n",
        "  y_source = pd.DataFrame(y_data)\n",
        "  df_new = source.iloc[:, [feature_to_filter_one,feature_to_filter_two]]\n",
        "  df_new['output'] = y_source\n",
        "  df_new.columns=[(f'Feature {feature_to_filter_one}'),(f'Feature {feature_to_filter_two}'), 'output']\n",
        "\n",
        "  st.subheader(f'Synthetic Data Scatter Plot of Features {feature_to_filter_one} and {feature_to_filter_two}')\n",
        "\n",
        "  st.write(alt.Chart(df_new).mark_circle(size=60).encode(\n",
        "      x=(f'Feature {feature_to_filter_one}'),\n",
        "      y=(f'Feature {feature_to_filter_two}'),\n",
        "      color='output',\n",
        "      tooltip=[(f'Feature {feature_to_filter_one}'), (f'Feature {feature_to_filter_two}'), 'output']\n",
        "  ).interactive())\n",
        "\n",
        "\n",
        "  #write the ML model to the web-app\n",
        "  X_train, X_test, y_train, y_test = train_test_split(source, y_source, test_size=0.2)\n",
        "\n",
        "\n",
        "  clf = svm.SVC(probability=True)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  for i in [X_test]:\n",
        "    y_guess = clf.predict_proba(X_test)\n",
        "\n",
        "\n",
        "  # Write the SHAP Plots into the web-app\n",
        "  st.subheader('SHAP Plots')\n",
        "\n",
        "  shap_graph = st.checkbox('Generate SHAP Summary Plot')\n",
        "\n",
        "  if shap_graph:\n",
        "    st.write('Calculating SHAP values...')\n",
        "    test_data = shap.sample(X_test, 15)\n",
        "    explainer = shap.KernelExplainer(clf.predict_proba, X_train[:15])\n",
        "    shap_values = explainer.shap_values(test_data)\n",
        "    st.write('SHAP values calculated!')\n",
        "    sum_plot = shap.summary_plot(shap_values, max_display=20)\n",
        "    st.pyplot(sum_plot)\n",
        "\n",
        "    st.subheader(f'Scatter Plot of SHAP Values of Features {feature_to_filter_one} and {feature_to_filter_two}')\n",
        "\n",
        "    shap_feature_one_class1 = []\n",
        "    shap_feature_two_class1 = []\n",
        "\n",
        "    shap_feature_one_class2 = []\n",
        "    shap_feature_two_class2 = []\n",
        "\n",
        "    for i in range(len(shap_values[0])):\n",
        "      shap_feature_one_class1.append(shap_values[0][i][feature_to_filter_one])\n",
        "      shap_feature_two_class1.append(shap_values[0][i][feature_to_filter_two])\n",
        "\n",
        "    for i in range(len(shap_values[1])):\n",
        "      shap_feature_one_class2.append(shap_values[1][i][feature_to_filter_one])\n",
        "      shap_feature_two_class2.append(shap_values[1][i][feature_to_filter_two])\n",
        "\n",
        "    merged = []\n",
        "\n",
        "    for i in range(len(shap_feature_one_class1)):\n",
        "      x = {f'Feature {feature_to_filter_one}': shap_feature_one_class1[i], f'Feature {feature_to_filter_two}': shap_feature_two_class1[i],'Class':0}\n",
        "      merged.append(x)\n",
        "      y = {f'Feature {feature_to_filter_one}': shap_feature_one_class2[i], f'Feature {feature_to_filter_two}': shap_feature_two_class2[i],'Class':1}\n",
        "      merged.append(y)\n",
        "\n",
        "    df_shap = pd.DataFrame(merged)\n",
        "\n",
        "    st.write(alt.Chart(df_shap).mark_circle(size=60).encode(\n",
        "        x = alt.X(f'Feature {feature_to_filter_one}'),\n",
        "        y = alt.Y(f'Feature {feature_to_filter_two}'),\n",
        "        color=alt.Color('Class:N', legend=alt.Legend(title=(\"Class\"))),\n",
        "    ).interactive())\n",
        "\n",
        "\n",
        "  # Write the LIME Plot into the Web-APP\n",
        "  st.subheader(\"LIME Plots\")\n",
        "\n",
        "  sample = st.slider('Pick an instance to analyze', 0, len(X_test), int(len(X_test)/5))\n",
        "\n",
        "  lime_graph = st.checkbox(\"Show LIME Graph\")\n",
        "\n",
        "  col_names = []\n",
        "  for i in range(source.shape[1]):\n",
        "    col_names.append(f'feature {i}')\n",
        "\n",
        "  if lime_graph:\n",
        "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "        training_data=X_train.values,\n",
        "        feature_names=col_names,\n",
        "        class_names=[\"Class 0\",\"Class 1\"],\n",
        "        mode=\"classification\",\n",
        "        verbose=True,\n",
        "        random_state=2022\n",
        "    )\n",
        "\n",
        "    num = sample\n",
        "    test_sample = X_test.iloc[num,:]\n",
        "    exp = lime_explainer.explain_instance(test_sample, predict_fn=clf.predict_proba, num_features=20, num_samples=100)\n",
        "    st.pyplot(exp.as_pyplot_figure(), clear_figure=False)\n",
        "    lime_graph = False\n",
        "\n",
        "\n",
        "\n",
        "# ALL CODE BELOW FOR REAL WORLD DATA\n",
        "else:\n",
        "  census_train = pd.read_csv(filepath_or_buffer=\"/content/drive/MyDrive/census-income.data\")\n",
        "  census_test = pd.read_csv(filepath_or_buffer=\"/content/drive/MyDrive/census-income.test\")\n",
        "\n",
        "\n",
        "  census_train = census_train.sample(n=80000,random_state=2)\n",
        "  census_test = census_test.sample(n=20000,random_state=2)\n",
        "\n",
        "\n",
        "  census_train.columns = census_test.columns = ['age','class_of_worker','detailed_industry_recode','detailed_occupation_recode','education','wage_per_hour','enrolled_in_edu_inst_last_wk',\n",
        "                          'marital_stat','major_industry_code','major_occupation_code','race','hispanic_origin','sex','member_of_a_labor_union','reason_for_unemployment',\n",
        "                          'full_or_part_time_employment_stat','capital_gains','capital_losses','dividends_from_stocks','tax_filer_stat','region_of_previous_residence',\n",
        "                          'state_of_previous_residence','detailed_household_and_family_stat','detailed_household_summary_in_household','instance_weight_ignore','instance_weight','migration_code-change_in_msa',\n",
        "                          'migration_code-change_in_reg','migration_code-move_within_reg','live_in_this_house_1_year_ago','migration_prev_res_in_sunbelt','num_persons_worked_for_employer',\n",
        "                          'family_members_under_18','country_of_birth_father','country_of_birth_mother','country_of_birth_self','citizenship','own_business_or_self_employed',\n",
        "                          'fill_inc_questionnaire_for_veterans_admin','veterans_benefits','weeks_worked_in_year','year']\n",
        "\n",
        "  census_train = census_train[census_train.wage_per_hour != 0]\n",
        "  census_test = census_test[census_test.wage_per_hour != 0]\n",
        "  \n",
        "  mean = census_train[\"wage_per_hour\"].mean()\n",
        "  census_train['wage_per_hour'] = census_train['wage_per_hour'].apply(lambda x: 1 if x > mean else 0)\n",
        "  census_test['wage_per_hour'] = census_test['wage_per_hour'].apply(lambda x: 1 if x > mean else 0)\n",
        "\n",
        "  options = []\n",
        "\n",
        "  columns_to_aggregate = st.multiselect(\n",
        "    'What features would you like to use?',\n",
        "      ['age','class_of_worker','education','major_industry_code','major_occupation_code','member_of_a_labor_union','capital_gains','capital_losses','dividends_from_stocks','weeks_worked_in_year'])\n",
        "  \n",
        "  options = columns_to_aggregate\n",
        "\n",
        "  if len(options) >= 2:\n",
        "    feature_to_filter_one = st.radio('Pick an x-axis feature', options, index=0)\n",
        "    feature_to_filter_two = st.radio('Pick an y-axis feature', options, index=1)\n",
        "\n",
        "    scat_df = census_train[[feature_to_filter_one,feature_to_filter_two,'wage_per_hour']]\n",
        "    class_color = []\n",
        "    for i in scat_df['wage_per_hour']:\n",
        "      if i == 0:\n",
        "        class_color.append('Class 0')\n",
        "      else:\n",
        "        class_color.append('Class 1')\n",
        "    \n",
        "    scat_df['Class'] = class_color\n",
        "\n",
        "    st.subheader((f'{feature_to_filter_one} vs {feature_to_filter_two}'))\n",
        "    st.subheader((f'Class 0: Earns below {int(mean)} per day'))\n",
        "    st.subheader((f' Class 1: Earns above {int(mean)} per day'))\n",
        "\n",
        "    st.write(alt.Chart(scat_df).mark_circle(size=30).encode(\n",
        "        x=(f'{feature_to_filter_one}'),\n",
        "        y=(f'{feature_to_filter_two}'),\n",
        "        color=alt.Color('Class', legend=alt.Legend(title=(\"Wage Class\"))),\n",
        "        tooltip=[(f'{feature_to_filter_one}'), (f'{feature_to_filter_two}'), 'Class']\n",
        "        ).properties(\n",
        "          width=800,\n",
        "          height=400\n",
        "        ).interactive())\n",
        "\n",
        "    if len(options) > 0:    \n",
        "      column_names = options\n",
        "      column_names.append('wage_per_hour')\n",
        "\n",
        "\n",
        "      #training set\n",
        "      census_train = census_train[column_names]\n",
        "\n",
        "      le = LabelEncoder() # label encoder \n",
        "      if 'class_of_worker' in options:\n",
        "        census_train['class_of_worker'] = le.fit_transform(census_train['class_of_worker'])\n",
        "      if 'education' in options:\n",
        "        census_train['education'] = le.fit_transform(census_train['education'])\n",
        "      if 'major_industry_code' in options:\n",
        "        census_train['major_industry_code'] = le.fit_transform(census_train['major_industry_code'])\n",
        "      if 'major_occupation_code' in options:\n",
        "        census_train['major_occupation_code'] = le.fit_transform(census_train['major_occupation_code'])\n",
        "      if 'member_of_a_labor_union' in options:\n",
        "        census_train['member_of_a_labor_union'] = le.fit_transform(census_train['member_of_a_labor_union'])\n",
        "      \n",
        "      le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "\n",
        "      X_train = census_train.drop(['wage_per_hour'], axis=1)\n",
        "      col_names = X_train.columns.values\n",
        "\n",
        "      s = MinMaxScaler()\n",
        "      X_train[X_train.columns] = s.fit_transform(X_train[X_train.columns])\n",
        "\n",
        "      y_train = census_train['wage_per_hour']\n",
        "\n",
        "      clf = svm.SVC(probability=True)\n",
        "      clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "      #testing set\n",
        "      census_test = census_test[column_names]\n",
        "\n",
        "      le = LabelEncoder() # label encoder \n",
        "      if 'class_of_worker' in options:\n",
        "        census_test['class_of_worker'] = le.fit_transform(census_test['class_of_worker'])\n",
        "      if 'education' in options:\n",
        "        census_test['education'] = le.fit_transform(census_test['education'])\n",
        "      if 'major_industry_code' in options:\n",
        "        census_test['major_industry_code'] = le.fit_transform(census_test['major_industry_code'])\n",
        "      if 'major_occupation_code' in options:\n",
        "        census_test['major_occupation_code'] = le.fit_transform(census_test['major_occupation_code'])\n",
        "      if 'member_of_a_labor_union' in options:\n",
        "        census_test['member_of_a_labor_union'] = le.fit_transform(census_test['member_of_a_labor_union'])\n",
        "\n",
        "      X_test = census_test.drop(['wage_per_hour'], axis=1)\n",
        "      col_names = X_test.columns.values\n",
        "\n",
        "      s = MinMaxScaler()\n",
        "      X_test[X_test.columns] = s.fit_transform(X_test[X_test.columns])\n",
        "\n",
        "      y_test = census_test['wage_per_hour']\n",
        "\n",
        "      clf = svm.SVC(probability=True)\n",
        "      clf.fit(X_test, y_test)\n",
        "\n",
        "\n",
        "      # Write the SHAP Plots into the web-app\n",
        "      st.subheader('SHAP Plots')\n",
        "\n",
        "      shap_graph = st.checkbox('Generate SHAP Summary Plot')\n",
        "\n",
        "    if shap_graph:\n",
        "    \n",
        "     \n",
        "      st.write('Calculating SHAP values...')\n",
        "      test_data = shap.sample(X_test, 15) \n",
        "      explainer = shap.KernelExplainer(clf.predict_proba, X_train[:15]) #gets first 15 records of X_train\n",
        "      shap_values = explainer.shap_values(test_data)\n",
        "      st.write('SHAP values calculated!')\n",
        "      sum_plot = shap.summary_plot(shap_values, feature_names = options)\n",
        "      st.pyplot(sum_plot)\n",
        "\n",
        "\n",
        "      st.subheader(f'Scatter Plot of SHAP Values of Features {feature_to_filter_one} and {feature_to_filter_two}')\n",
        "\n",
        "      shap_feature_one_class1 = []\n",
        "      shap_feature_two_class1 = []\n",
        "\n",
        "      shap_feature_one_class2 = []\n",
        "      shap_feature_two_class2 = []\n",
        "\n",
        "      for i in range(len(shap_values[0])):\n",
        "        shap_feature_one_class1.append(shap_values[0][i][options.index(feature_to_filter_one)])\n",
        "        shap_feature_two_class1.append(shap_values[0][i][options.index(feature_to_filter_two)])\n",
        "\n",
        "      for i in range(len(shap_values[1])):\n",
        "        shap_feature_one_class2.append(shap_values[1][i][options.index(feature_to_filter_one)])\n",
        "        shap_feature_two_class2.append(shap_values[1][i][options.index(feature_to_filter_two)])\n",
        "\n",
        "      merged = []\n",
        "\n",
        "      for i in range(len(shap_feature_one_class1)):\n",
        "        x = {f'Feature {feature_to_filter_one}': shap_feature_one_class1[i], f'Feature {feature_to_filter_two}': shap_feature_two_class1[i],'Class':0}\n",
        "        merged.append(x)\n",
        "        y = {f'Feature {feature_to_filter_one}': shap_feature_one_class2[i], f'Feature {feature_to_filter_two}': shap_feature_two_class2[i],'Class':1}\n",
        "        merged.append(y)\n",
        "\n",
        "      df_shap = pd.DataFrame(merged)\n",
        "\n",
        "      st.write(alt.Chart(df_shap).mark_circle(size=60).encode(\n",
        "          x = alt.X(f'Feature {feature_to_filter_one}'),\n",
        "          y = alt.Y(f'Feature {feature_to_filter_two}'),\n",
        "          color=alt.Color('Class:N', legend=alt.Legend(title=(\"Class\"))),\n",
        "      ).interactive())\n",
        "\n",
        "\n",
        "\n",
        "      # Write the LIME Plot into the Web-APP\n",
        "      st.subheader(\"LIME Plots\")\n",
        "\n",
        "      sample = st.slider('Pick an instance to analyze', 0, len(X_test), int(len(X_test)/5))\n",
        "\n",
        "      lime_graph = st.checkbox(\"Show LIME Graph\")\n",
        "\n",
        "      if lime_graph:\n",
        "        lime_explainer = lime_tabular.LimeTabularExplainer(\n",
        "            training_data=X_train.values,\n",
        "            feature_names=options,\n",
        "            class_names=[(f\"Wage Above {mean}\"),(f\"Wage Below {mean}\")],\n",
        "            mode=\"classification\",\n",
        "            verbose=True,\n",
        "            random_state=2022\n",
        "          )\n",
        "        num = 2\n",
        "        test_sample = X_test.iloc[num,:]\n",
        "        exp = lime_explainer.explain_instance(test_sample, predict_fn=clf.predict_proba, num_features=10, num_samples=100)\n",
        "        st.pyplot(exp.as_pyplot_figure(), clear_figure=False)\n",
        "        lime_graph = False\n",
        "        st.write(le_name_mapping)\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVlH5wDmXGSv",
        "outputId": "4f22e0d5-9de5-4bb1-d2d5-1aae58897cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oelfLU4RXHNt",
        "outputId": "b97e5505-57e6-4fd7-9a4e-8aac7602335e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-13 01:49:41.368 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.897s\n",
            "your url is: https://nice-crews-carry-35-231-246-201.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.231.246.201:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    }
  ]
}